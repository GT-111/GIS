{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "# cudf\n",
    "import cudf\n",
    "from utils.data_preprocess_utils import get_config, get_all_files\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_preprocess_utils as pre\n",
    "import concurrent.futures\n",
    "\n",
    "def preprocess_csv(file_path, cfg):\n",
    "    # print('Preprocessing: ', file_path)\n",
    "    df = cudf.read_csv(file_path, usecols=cfg.colums_to_extract)\n",
    "    df['# Timestamp'] = df['# Timestamp'].astype('datetime64[ns]')\n",
    "    # Data Cleaning\n",
    "    df = pre.rename_columns(df, cfg)\n",
    "    df = pre.drop_duplicates(df)\n",
    "    df = pre.filter_missing_value(df, cfg.colums_to_drop_na)\n",
    "    df = pre.filter_mmsi(df)\n",
    "    df = pre.rmove_outlinears(df=df, LAT_MIN=cfg.LAT_MIN, LAT_MAX=cfg.LAT_MAX, LON_MIN=cfg.LON_MIN, LON_MAX=cfg.LON_MAX)\n",
    "    df = pre.filter_minority(df=df, threshold=cfg.traj_points_threshold, column='MMSI')\n",
    "    df = pre.filter_SOG(df=df, SOG_threshold=cfg.SOG_threshold)\n",
    "    # print('Data Cleaning Done!')\n",
    "    df = df.to_pandas()\n",
    "    # Data Completion\n",
    "    df = pre.complete_missing_value(cfg=cfg, df=df)\n",
    "    # print('Data Completion Done!')\n",
    "    # df = pre.trans2cat(df)\n",
    "    df = df.sort_values(by=['MMSI', 'time']).reset_index(drop=True)\n",
    "    # Calc Nautical Distance\n",
    "    df['distance'] = df.groupby('MMSI').apply(pre.haversine_distance).reset_index(drop=True)\n",
    "    # Calc Time Diff\n",
    "    df['SOG_diff'] = df.groupby('MMSI')['SOG'].diff(periods=1).fillna(0)\n",
    "    # Calc COG Diff\n",
    "    df['COG_diff'] = df.groupby('MMSI')['COG'].diff(periods=1).fillna(0)\n",
    "    # if abs(COG_diff) > 180, COG_diff = 360 - abs(COG_diff)\n",
    "    df['COG_diff'] = df['COG_diff'].apply(lambda x: abs(x) if abs(x) < 180 else 360 - abs(x))\n",
    "    # Calc Time Diff\n",
    "    df['time_diff'] = df.groupby('MMSI')['time'].diff(periods=1)\n",
    "    # Calc Distance Diff\n",
    "    df['distance_diff'] = df.groupby('MMSI')['distance'].diff(periods=1).fillna(0).abs()\n",
    "    # Split Trips\n",
    "    df['trips_id'] = df.groupby('MMSI').apply(pre.split_trips, cfg=cfg).reset_index(drop=True)\n",
    "    df = df.sort_values(by=['trips_id', 'time']).reset_index(drop=True)\n",
    "    df = pre.filter_minority(df=df, threshold=cfg.trip_points_threshold, column='trips_id')\n",
    "\n",
    "    preprocessed_file_path = cfg.out_dir + file_path.split('/')[-1].split('.')[0] + '.feather'\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_feather(preprocessed_file_path)\n",
    "    print('Preprocessed file saved: ', preprocessed_file_path)\n",
    "    return None\n",
    "\n",
    "def process_file(file_path, start_date, end_date, cfg):\n",
    "    try:\n",
    "        yyyy, mm, dd = file_path.split('/')[-1].split('.')[0].split('-')[1:]\n",
    "        # print(yyyy, mm, dd)\n",
    "        if dd is not None:\n",
    "            date = pd.to_datetime(yyyy+'-'+mm+'-'+dd)\n",
    "        else:\n",
    "            date = pd.to_datetime(yyyy+'-'+mm)\n",
    "        if date >= pd.to_datetime(start_date) and date <= pd.to_datetime(end_date):\n",
    "            # print('Processing: ', file_path)\n",
    "            preprocess_csv(file_path, cfg)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "\n",
    "def preprocess_csvs(data_dir, start_date, end_date, cfg):\n",
    "    file_paths = get_all_files(data_dir)\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    print('Start Preprocessing...')\n",
    "    print('Start Date: ', start_date)\n",
    "    print('End Date: ', end_date)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = [executor.submit(process_file, file_path, start_date, end_date, cfg) for file_path in file_paths]\n",
    "        # Wait for all threads to finish\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "\n",
    "\n",
    "cfg = edict(get_config('./cfg/data_preprocess_cfg.yaml'))\n",
    "preprocess_csvs(cfg.in_dir, '2019-01-01', '2019-03-31', cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
